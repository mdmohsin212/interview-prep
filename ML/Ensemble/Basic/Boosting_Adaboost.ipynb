{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957bc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53da3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=1000, n_classes=2, weights=[0.7, 0.3], random_state=42)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7715a5a",
   "metadata": {},
   "source": [
    "**AdaBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97babe0",
   "metadata": {},
   "source": [
    "**Weight Calculation:**\n",
    "$$\\alpha_t = \\frac{1}{2} \\ln\\left(\\frac{1 - \\varepsilon_t}{\\varepsilon_t}\\right)$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha_t$: Weight of $t$-th weak learner\n",
    "- $\\varepsilon_t$: Error rate of $t$-th weak learner\n",
    "\n",
    "**Instance Weight Update:**\n",
    "$$w_i^{(t+1)} = \\frac{w_i^{(t)} \\exp(-\\alpha_t \\cdot y_i \\cdot h_t(x_i))}{Z_t}$$\n",
    "\n",
    "Where:\n",
    "- $w_i$: Weight of instance $i$\n",
    "- $y_i$: True label\n",
    "- $h_t(x_i)$: Prediction of $t$-th learner\n",
    "- $Z_t$: Normalization factor\n",
    "\n",
    "**Final Prediction:**\n",
    "$$H(x) = \\text{sign}\\left(\\sum_t \\alpha_t \\cdot h_t(x)\\right)$$\n",
    "\n",
    "Where:\n",
    "- $H(x)$: Final prediction\n",
    "- $h_t(x)$: Prediction of $t$-th learner\n",
    "- $\\alpha_t$: Weight of $t$-th learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f45e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    algorithm='SAMME',\n",
    "    random_state=42\n",
    ")\n",
    "adaboost.fit(x_train, y_train)\n",
    "y_pred = adaboost.predict(x_test)\n",
    "print(f\"AdaBoost Accuracy: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa2862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "       feature  importance\n",
      "5    feature_5    0.308520\n",
      "14  feature_14    0.173387\n",
      "1    feature_1    0.106111\n",
      "10  feature_10    0.080602\n",
      "6    feature_6    0.054288\n",
      "0    feature_0    0.039846\n",
      "17  feature_17    0.038460\n",
      "11  feature_11    0.035936\n",
      "2    feature_2    0.031066\n",
      "13  feature_13    0.024249\n",
      "8    feature_8    0.023117\n",
      "18  feature_18    0.023043\n",
      "12  feature_12    0.021761\n",
      "15  feature_15    0.021258\n",
      "7    feature_7    0.018356\n",
      "3    feature_3    0.000000\n",
      "9    feature_9    0.000000\n",
      "4    feature_4    0.000000\n",
      "16  feature_16    0.000000\n",
      "19  feature_19    0.000000\n"
     ]
    }
   ],
   "source": [
    "importance = pd.DataFrame({\n",
    "    'feature': [f\"feature_{i}\" for i in range(x_train.shape[1])],\n",
    "    'importance': adaboost.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05b59dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimator Weights (first 5): [2.19722458 0.51972446 0.60663303 0.66779734 0.68589935]\n"
     ]
    }
   ],
   "source": [
    "# Estimator weights (how much each model contributes)\n",
    "print(f\"\\nEstimator Weights (first 5): {adaboost.estimator_weights_[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d57db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error Rate by Stage:\n",
      "Stage 1: Error=0.140, Weight=2.197\n",
      "Stage 2: Error=0.300, Weight=0.520\n",
      "Stage 3: Error=0.260, Weight=0.607\n",
      "Stage 4: Error=0.460, Weight=0.668\n",
      "Stage 5: Error=0.595, Weight=0.686\n",
      "Stage 6: Error=0.185, Weight=0.609\n",
      "Stage 7: Error=0.385, Weight=0.494\n",
      "Stage 8: Error=0.415, Weight=0.388\n",
      "Stage 9: Error=0.460, Weight=0.448\n",
      "Stage 10: Error=0.640, Weight=0.542\n"
     ]
    }
   ],
   "source": [
    "# Error rate at each stage\n",
    "print(\"\\nError Rate by Stage:\")\n",
    "for i, estimator in enumerate(adaboost.estimators_[:10]):\n",
    "    stage_pred = estimator.predict(x_test)\n",
    "    error = 1 - accuracy_score(y_test, stage_pred)\n",
    "    weight = adaboost.estimator_weights_[i]\n",
    "    print(f\"Stage {i+1}: Error={error:.3f}, Weight={weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b6c67",
   "metadata": {},
   "source": [
    "**AdaBoost Components in Detail**\n",
    "1. Weak Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413507d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision stumps (depth 1)\n",
    "stump = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Or use other weak learners\n",
    "adaboost_nb = AdaBoostClassifier(\n",
    "    estimator=GaussianNB(),\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f05f31",
   "metadata": {},
   "source": [
    "2. Learning Rate\n",
    "\n",
    "    ```\n",
    "    Lower learning rate = more conservative updates\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e9c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.5: 0.875\n",
      "Learning Rate 1.0: 0.870\n",
      "Learning Rate 1.5: 0.840\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.5, 1.0, 1.5]\n",
    "for lr in learning_rate:\n",
    "    model = AdaBoostClassifier(\n",
    "        n_estimators=50,\n",
    "        learning_rate=lr,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    score = model.score(x_test, y_test)\n",
    "    print(f\"Learning Rate {lr}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229964f6",
   "metadata": {},
   "source": [
    "3. Number of Estimators\n",
    "    \n",
    "    ```\n",
    "    More estimators = better but slower\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8450ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators 10: 0.870\n",
      "n_estimators 25: 0.870\n",
      "n_estimators 50: 0.870\n",
      "n_estimators 100: 0.875\n",
      "n_estimators 200: 0.875\n"
     ]
    }
   ],
   "source": [
    "n_estimator_list = [10, 25, 50, 100, 200]\n",
    "for n in n_estimator_list:\n",
    "    model = AdaBoostClassifier(n_estimators=n, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    score = model.score(x_test, y_test)\n",
    "    print(f\"n_estimators {n}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c7b89",
   "metadata": {},
   "source": [
    "**AdaBoost for Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_reg = AdaBoostRegressor(\n",
    "    estimator=None,\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,\n",
    "    loss='linear',  # 'linear', 'square', 'exponential'\n",
    "    random_state=42\n",
    ")\n",
    "adaboost_reg.fit(x_train, y_train)\n",
    "y_pred = adaboost_reg.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
