{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad524f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=1000, n_classes=2, weights=[0.7, 0.3], n_features=10, random_state=42)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98be852",
   "metadata": {},
   "source": [
    "**Tuning Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b62576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 100}\n",
      "Best score: 0.935\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_random.fit(x_train, y_train)\n",
    "print(f\"Best params: {rf_random.best_params_}\")\n",
    "print(f\"Best score: {rf_random.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954b7e2",
   "metadata": {},
   "source": [
    "**Tuning XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05942318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost params: {'subsample': 1.0, 'reg_lambda': 1.5, 'reg_alpha': 0.1, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "xgb_grid = RandomizedSearchCV(\n",
    "    XGBClassifier(random_state=42),\n",
    "    xgb_param_grid,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "    \n",
    "xgb_grid.fit(x_train, y_train)\n",
    "print(f\"Best XGBoost params: {xgb_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698f63c",
   "metadata": {},
   "source": [
    "**Tuning Stacking Meta-Learner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9608498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.934 (+/- 0.015)\n",
      "Ridge: 0.935 (+/- 0.013)\n",
      "SVM: 0.934 (+/- 0.013)\n",
      "\n",
      "Best meta-learner: Ridge\n"
     ]
    }
   ],
   "source": [
    "# Tune meta-learner in stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Try different meta-learners\n",
    "meta_learners = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Ridge': RidgeClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "best_meta = None\n",
    "best_score = 0\n",
    "\n",
    "for name, meta in meta_learners.items():\n",
    "    stacking = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=meta,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        stacking, x_train, y_train,\n",
    "        cv=5, scoring='accuracy', n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    if scores.mean() > best_score:\n",
    "        best_score = scores.mean()\n",
    "        best_meta = name\n",
    "    \n",
    "    print(f\"{name}: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "\n",
    "print(f\"\\nBest meta-learner: {best_meta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
