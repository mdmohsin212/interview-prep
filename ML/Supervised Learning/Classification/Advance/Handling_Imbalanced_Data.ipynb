{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f356c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243cecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "0    897\n",
      "1    103\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Baseline (always predict majority): 0.897\n"
     ]
    }
   ],
   "source": [
    "# Create imbalanced dataset (90% class 0, 10% class 1)\n",
    "\n",
    "x, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(pd.Series(y).value_counts())\n",
    "print(f\"\\nBaseline (always predict majority): {max(pd.Series(y).value_counts()) / len(y):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b5e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (imbalanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       180\n",
      "           1       0.46      0.30      0.36        20\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.69      0.63      0.65       200\n",
      "weighted avg       0.88      0.90      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"\\nClassification Report (imbalanced):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d9a76",
   "metadata": {},
   "source": [
    "**Solution 1: Class Weights**\n",
    "-  Option 1: Balanced weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With balanced class weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       180\n",
      "           1       0.41      0.75      0.53        20\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.69      0.81      0.72       200\n",
      "weighted avg       0.91      0.86      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_balanced = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "model_balanced.fit(x_train, y_train)\n",
    "y_pred_balanced = model_balanced.predict(x_test)\n",
    "\n",
    "print(\"\\nWith balanced class weights:\")\n",
    "print(classification_report(y_test, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619bfd7",
   "metadata": {},
   "source": [
    "- Option 2: Custom weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3325aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With Custom class weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.91       180\n",
      "           1       0.38      0.75      0.51        20\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.68      0.81      0.71       200\n",
      "weighted avg       0.91      0.85      0.87       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_custom = LogisticRegression(\n",
    "    class_weight={0:1, 1:10},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_custom.fit(x_train, y_train)\n",
    "y_pred_custom = model_custom.predict(x_test)\n",
    "\n",
    "print(\"\\nWith Custom class weights:\")\n",
    "print(classification_report(y_test, y_pred_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca69730",
   "metadata": {},
   "source": [
    "**Solution 2: Resampling**\n",
    "- Oversampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79de38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Resample :\n",
      "0    717\n",
      "1    717\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "\n",
    "smote = SMOTE()\n",
    "x_resample, y_resample = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('After Resample :')\n",
    "print(pd.Series(y_resample).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "952380ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       180\n",
      "           1       0.42      0.75      0.54        20\n",
      "\n",
      "    accuracy                           0.87       200\n",
      "   macro avg       0.69      0.82      0.73       200\n",
      "weighted avg       0.91      0.87      0.89       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_smote = LogisticRegression(random_state=42)\n",
    "model_smote.fit(x_resample, y_resample)\n",
    "\n",
    "y_pred_smote = model_smote.predict(x_test)\n",
    "\n",
    "print(\"\\nWith SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a44f57",
   "metadata": {},
   "source": [
    "- Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09bf6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling:\n",
      "0    83\n",
      "1    83\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "x_under, y_under = undersampler.fit_resample(x_train, y_train)\n",
    "\n",
    "print(\"After undersampling:\")\n",
    "print(pd.Series(y_under).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6baea",
   "metadata": {},
   "source": [
    "- Combined (SMOTE + Tomek Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca9cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE + Tomek Links:\n",
      "0    716\n",
      "1    716\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "x_combined, y_combined = smote_tomek.fit_resample(x_train, y_train)\n",
    "\n",
    "print(\"After SMOTE + Tomek Links:\")\n",
    "print(pd.Series(y_combined).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272005b",
   "metadata": {},
   "source": [
    "**Solution 3: Threshold Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f00ee045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.127\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Find optimal threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Find threshold that maximizes F1-score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_idx = np.argmax(f1_score)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e6b9590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With optimal threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       180\n",
      "           1       0.45      0.75      0.57        20\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.71      0.82      0.75       200\n",
      "weighted avg       0.92      0.89      0.90       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use optimal threshold\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"\\nWith optimal threshold:\")\n",
    "print(classification_report(y_test, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98402c6e",
   "metadata": {},
   "source": [
    "**Comparison of Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75555f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline       : F1-Score = 0.364\n",
      "Class Weights  : F1-Score = 0.526\n",
      "SMOTE          : F1-Score = 0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "methods = {\n",
    "    'Baseline': model,\n",
    "    'Class Weights': model_balanced,\n",
    "    'SMOTE': model_smote\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model_method in methods.items():\n",
    "    y_pred_method = model_method.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred_method)\n",
    "    results[name] = f1\n",
    "    print(f\"{name:15s}: F1-Score = {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
