{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GIalXTYiI4Ig"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = yf.download(\"BTC-USD\", start=\"2020-01-01\", end=\"2025-01-01\")\n",
        "\n",
        "data = df[\"Close\"]\n",
        "\n",
        "bitcoin_prices = df[\"Close\"].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5iXl7MDLIXt",
        "outputId": "cdd0c236-8434-4739-8d18-afc52eb00bab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1722763981.py:1: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(\"BTC-USD\", start=\"2020-01-01\", end=\"2025-01-01\")\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Time Series Data**\n",
        "\n",
        "- Creating Windows and Labels:"
      ],
      "metadata": {
        "id": "A0C0WEA4J6q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_windows_labels(time_series, window_size=7, horizon=1):\n",
        "    windows = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(len(time_series) - window_size - horizon + 1):\n",
        "        windows.append(time_series[i:i+window_size])\n",
        "        labels.append(time_series[i+window_size:i+window_size+horizon])\n",
        "\n",
        "    return np.array(windows), np.array(labels)\n",
        "\n",
        "\n",
        "windows, labels = create_windows_labels(bitcoin_prices, window_size=7, horizon=1)\n",
        "\n",
        "\n",
        "print(f\"Windows shape: {windows.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBu8mw_1J3id",
        "outputId": "812df63c-7da5-46cf-b077-e0485b3333b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Windows shape: (1820, 7, 1)\n",
            "Labels shape: (1820, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time-Based Train/Test Split:**"
      ],
      "metadata": {
        "id": "DuXGWAInLn12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_date = '2023-01-01'\n",
        "train_data = data[data.index < split_date]\n",
        "test_data = data[data.index >= split_date]\n",
        "\n",
        "train_windows, train_labels = create_windows_labels(train_data.values, window_size=7)\n",
        "test_windows, test_labels = create_windows_labels(test_data.values, window_size=7)"
      ],
      "metadata": {
        "id": "DM0GilmlLPKn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Time Series Models**\n",
        "\n",
        "- Model 0: Naive Forecast (Baseline):"
      ],
      "metadata": {
        "id": "Lc7SNwPPNB7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_forecast(data, horizon=1):\n",
        "    return data[-horizon:]\n",
        "\n",
        "naive_pred = naive_forecast(train_data.values, horizon=len(test_data))"
      ],
      "metadata": {
        "id": "lmbpao5OMQt-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model 1: Dense Model:"
      ],
      "metadata": {
        "id": "kwXSu2CxNYdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(7,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_1.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mae',\n",
        "    metrics=['mae', 'mse']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWSJu6oRNXLH",
        "outputId": "6edfa7a0-c994-4878-e0d1-bfd8d019e09f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model 2: LSTM for Time Series:"
      ],
      "metadata": {
        "id": "gaeyskbyN1f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = keras.Sequential([\n",
        "    layers.LSTM(64, activation='relu', input_shape=(7, 1), return_sequences=True),\n",
        "    layers.LSTM(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Reshape data for LSTM (needs 3D: samples, timesteps, features)\n",
        "train_windows_lstm = train_windows.reshape(-1, 7, 1)\n",
        "test_windows_lstm = test_windows.reshape(-1, 7, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl5boVSHNz0B",
        "outputId": "5a60269c-ed92-4c2f-b953-06bdc0673aaa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model 3: Conv1D for Time Series:"
      ],
      "metadata": {
        "id": "XKmObQt_OfFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = keras.Sequential([\n",
        "    layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(7, 1)),\n",
        "    layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhGneuAIOdrX",
        "outputId": "d7e062d3-24d3-4a3f-cd71-34336daa007c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model 4: Multivariate Time Series:"
      ],
      "metadata": {
        "id": "QruMVnYsO72L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multivariate_data = np.column_stack([price, volume, sentiment])\n",
        "\n",
        "def create_multivariate_windows(data, window_size=7, horizon=1):\n",
        "    windows = []\n",
        "    labels = []\n",
        "    for i in range(len(data) - window_size - horizon + 1):\n",
        "        windows.append(data[i:i+window_size])\n",
        "        labels.append(data[i+window_size:i+window_size+horizon, 0])\n",
        "    return np.array(windows), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "multivariate_windows, multivariate_labels = create_multivariate_windows(\n",
        "    multivariate_data, window_size=7\n",
        ")"
      ],
      "metadata": {
        "id": "juAe94pRO3ZB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = keras.Sequential([\n",
        "    layers.LSTM(64, input_shape=(7, 3)),\n",
        "    layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbmeojy1P7PJ",
        "outputId": "12673432-135f-4478-ec4a-8ded15ba30d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time Series Evaluation Metrics**"
      ],
      "metadata": {
        "id": "sZ14be4xQBth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_time_series_forecast(y_true, y_pred):\n",
        "    mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred).numpy()\n",
        "    mse = tf.keras.metrics.mean_squared_error(y_true, y_pred).numpy()\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # Mean Absolute Percentage Error (MAPE)\n",
        "    mape = tf.reduce_mean(tf.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "    # MASE = MAE / MAE of naive forecast\n",
        "    naive_mae = tf.reduce_mean(tf.abs(y_true[1:] - y_true[:-1]))\n",
        "    mase = mae / naive_mae\n",
        "\n",
        "    return {\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAPE': mape,\n",
        "        'MASE': mase\n",
        "    }"
      ],
      "metadata": {
        "id": "6zT22mQnQADb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Advanced: N-BEATS Algorithm\n",
        "\n",
        "**N-BEATS (Neural Basis Expansion Analysis):**"
      ],
      "metadata": {
        "id": "qQTUtn51QscF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NBeatsBlock(layers.Layer):\n",
        "    def __init__(self, input_size, theta_size, horizon, n_neurons, n_layers, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.input_size = input_size\n",
        "        self.theta_size = theta_size\n",
        "        self.horizon = horizon\n",
        "        self.n_neurons = n_neurons\n",
        "\n",
        "        self.hidden = [layers.Dense(n_neurons, activation='relu') for _ in range(n_layers)]\n",
        "        self.theta_layer = layers.Dense(theta_size, activation='linear', name='theta')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.hidden:\n",
        "            x = layer(x)\n",
        "        theta = self.theta_layer(x)\n",
        "        backcast, forecast = self.lambda_layer(theta)\n",
        "        return backcast, forecast\n",
        "\n",
        "    def lambda_layer(self, theta):\n",
        "        backcast_basis = tf.ones([self.input_size, self.theta_size])\n",
        "        forecast_basis = tf.ones([self.horizon, self.theta_size])\n",
        "\n",
        "        backcast = tf.einsum('bp,pt->bt', theta, backcast_basis)\n",
        "        forecast = tf.einsum('bp,pt->bt', theta, forecast_basis)\n",
        "        return backcast, forecast"
      ],
      "metadata": {
        "id": "7irS463BQc0t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_nbeats_model(input_size, horizon, n_block=4):\n",
        "    inputs = layers.Input(shape=(input_size,))\n",
        "    residuals = inputs\n",
        "    forecasts = []\n",
        "\n",
        "    for i in range(n_block):\n",
        "        block = NBeatsBlock(\n",
        "            input_size=input_size,\n",
        "            theta_size=input_size + horizon,\n",
        "            horizon=horizon,\n",
        "            n_neurons=512,\n",
        "            n_layers=4\n",
        "        )\n",
        "        backcast, forecast = block(residuals)\n",
        "        residuals = layers.Subtract()([residuals, backcast])\n",
        "        forecasts.append(forecast)\n",
        "\n",
        "    forecast = layers.Add()(forecasts)\n",
        "    model = keras.Model(inputs, forecast)\n",
        "    return model"
      ],
      "metadata": {
        "id": "lr-iHrWPR4u7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ensemble Models for Time Series**"
      ],
      "metadata": {
        "id": "Rjg7FksaU_83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model_1, model_2, model_3]\n",
        "\n",
        "predictions = []\n",
        "for model in models:\n",
        "    pred = model.predict(test_windows)\n",
        "    predictions.append(pred)\n",
        "\n",
        "# Ensemble: Average predictions\n",
        "ensemble_pred = np.mean(predictions, axis=0)\n",
        "\n",
        "\n",
        "# Or weighted ensemble\n",
        "weights = [0.3, 0.4, 0.3]\n",
        "ensemble_pred = np.average(predictions, axis=0, weights=weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AP3zvURU-qg",
        "outputId": "9705723d-efba-4b95-bd84-d9ac4044d117"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction Intervals**"
      ],
      "metadata": {
        "id": "s46OvHqTVk-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction_intervals(predictions, confidence=0.95):\n",
        "    alpha = 1 - confidence\n",
        "    lower_percentile = (alpha / 2) * 100\n",
        "    upper_percentile = (1 - alpha / 2) * 100\n",
        "\n",
        "    lower_bound = np.percentile(predictions, lower_percentile, axis=0)\n",
        "    upper_bound = np.percentile(predictions, upper_percentile, axis=0)\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "\n",
        "lower, upper = get_prediction_intervals(ensemble_pred, confidence=0.95)"
      ],
      "metadata": {
        "id": "2R9QTsvqVh0u"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}