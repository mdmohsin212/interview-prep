{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ETmLIlZvGpSJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Dataset Class**"
      ],
      "metadata": {
        "id": "_AxhrFW7JuNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None, target_transform=None):\n",
        "        super().__init__()\n",
        "        self.image_dir = image_dir\n",
        "        self.image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self._get_label(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def _get_label(self, image_path):\n",
        "        return 0"
      ],
      "metadata": {
        "id": "oy8fjww0Hh2v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation**"
      ],
      "metadata": {
        "id": "wDM0cD57Jq1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training transforms (with augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Test transforms (no augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "train_data = CustomImageDataset(image_dir='train', transform=train_transform)\n",
        "test_data = CustomImageDataset(image_dir='test', transform=test_transform)"
      ],
      "metadata": {
        "id": "hzr5rS2YLlPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}